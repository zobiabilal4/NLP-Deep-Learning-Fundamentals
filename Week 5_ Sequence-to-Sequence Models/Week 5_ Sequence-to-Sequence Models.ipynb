{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1228e8b1",
   "metadata": {},
   "source": [
    "# Week 5_ Sequence-to-Sequence Models\n",
    "\n",
    "- Introduction to sequence-to-sequence models and its architecture\n",
    "- Understanding of Encoder-Decoder Models and its variants\n",
    "- Introduction to attention mechanism and its role in sequence-to-sequence models\n",
    "- Understanding of Beam Search and its application in sequence-to-sequence models\n",
    "- Implementing machine translation models using PyTorch or TensorFlow\n",
    "- Understanding of evaluation metrics for machine translation\n",
    "- Understanding of transfer learning and fine-tuning pre-trained models for machine translation tasks\n",
    "- Introduction to unsupervised machine translation and its techniques\n",
    "- Understanding of Multilingual models and its application in NLP tasks\n",
    "- Understanding the concept of zero-shot learning and its application in machine translation tasks\n",
    "- Understanding the concept of back-translation and its application in machine translation tasks\n",
    "- Understanding the concept of ensembling in machine translation tasks\n",
    "- Understanding the concept of language model pre-training and its application in machine translation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92890111",
   "metadata": {},
   "source": [
    "##  Sequence-to-sequence models and its architecture\n",
    "\n",
    "Sequence to Sequence (often abbreviated to seq2seq) models is a special class of Recurrent Neural Network architectures that we typically use (but not restricted) to solve complex Language problems like Machine Translation, Question Answering, creating Chatbots, Text Summarization, etc.\n",
    "\n",
    "<img src=\"images/sequence.jpg\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://miro.medium.com/v2/resize:fit:669/0*iDgmgGnrzq65dPXy.jpg)\n",
    "\n",
    "\n",
    "<img src=\"images/sequence 1.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://miro.medium.com/v2/resize:fit:700/1*y4D1XNJQmx-Gii1oHeHy_A.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53325aa",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Models and its variants\n",
    "\n",
    "#### The Encoder-Decoder Network\n",
    "\n",
    "This network have been applied to very wide range of applications including machine translation, text summarisation, questioning answering and dialogue. Let’s try to understand the idea underlying the encoder-decoder networks. The encoder takes the input sequence and creates a contextual representation (which is also called context) of it and the decoder takes this contextual representation as input and generates output sequence.\n",
    "\n",
    "<img src=\"images/encoder decoder core.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "### Encoder:\n",
    "\n",
    "Encoder takes the input sequence and generated a context which is the essence of the input to the decoder.\n",
    "\n",
    "<img src=\"images/encoder.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "The entire purpose of the encoder is to generate a contextual representation/ context for the input sequence.\n",
    "\n",
    "### Decoder:\n",
    "\n",
    "Decoder takes the context as input and generates a sequence of output. When we employ RNN as decoder, the context is the final hidden state of the RNN encoder.\n",
    "\n",
    "<img src=\"images/decoder.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "The first decoder RNN cell takes “CONTEXT” as its prior hidden state. The decoder then generated the output until the end-of-sequence marker is generated.\n",
    "\n",
    "- complete encoder decoder model\n",
    "\n",
    "<img src=\"images/complete encoder decoder.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "<img src=\"images/encoder decoder 2.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://towardsdatascience.com/what-is-an-encoder-decoder-model-86b3d57c5e1a)\n",
    "\n",
    "### Types of Encoders and Decoders\n",
    "\n",
    "There are two main types of encoder and decoder: \n",
    "- Linear \n",
    "- Nonlinear\n",
    "\n",
    "#### Linear encoders and decoders:\n",
    "\n",
    "These are the most common type. They work by taking an input signal and converting it into an output signal that is proportional to the input.\n",
    "\n",
    "#### Nonlinear encoders and decoders:\n",
    "\n",
    "These are less common but are more versatile. They work by taking an input signal and converting it into an output signal that is not proportional to the input.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bedd899",
   "metadata": {},
   "source": [
    "## Introduction to attention mechanism and its role in sequence-to-sequence models\n",
    "\n",
    "<img src=\"images/attention mechanism.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://miro.medium.com/v2/resize:fit:1022/1*qhOlQHLdtfZORIXYuoCtaA.png)\n",
    "\n",
    "\n",
    "\n",
    "Seq2Seq model with an attention mechanism consists of an encoder, decoder, and attention layer.\n",
    "\n",
    "Attention layer consists of\n",
    "\n",
    "- Alignment layer\n",
    "- Attention weights\n",
    "- Context vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd36cd",
   "metadata": {},
   "source": [
    "## Understanding of Beam Search and its application in sequence-to-sequence models\n",
    "\n",
    "\n",
    "<img src=\"images/beam1.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/@dhartidhami/beam-search-in-seq2seq-model-7606d55b21a5)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/beam2.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/@dhartidhami/beam-search-in-seq2seq-model-7606d55b21a5)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/beam3.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/@dhartidhami/beam-search-in-seq2seq-model-7606d55b21a5)\n",
    "\n",
    "\n",
    "### APPLICATIONS \n",
    "\n",
    "A beam search is most often used to maintain tractability in large systems with insufficient memory to store the entire search tree.For example, \n",
    "- It has been used in many machine translation systems.\n",
    "- Each part is processed to select the best translation, and many different ways of translating the words appear.\n",
    "- According to their sentence structures, the top best translations are kept, and the rest are discarded. The translator then evaluates the translations according to a given criterion, choosing the translation which best keeps the goals.\n",
    "- The first use of a beam search was in the Harpy Speech Recognition System, CMU 1976."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2e20b",
   "metadata": {},
   "source": [
    " ## Evaluation metrics for machine translation\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "<img src=\"images/evaluation matrices.png\"  width =\"1000px\" height =\"1000px\">\n",
    "\n",
    "Image source: [Link to source](https://www.mdpi.com/2227-7390/11/4/1006)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b56afe",
   "metadata": {},
   "source": [
    "## Transfer learning and fine-tuning pre-trained models for machine translation tasks\n",
    "\n",
    "\n",
    "<img src=\"images/transferlearning.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/616b35e3dcd432047dd02ea5_uYLdnVpAfjC3DC7eWJM2xWyQin_dbVcak0JlRpd7S2bAkdylh-9JITWttww3Wq8fKI56Tl3_v7Y-aVh4nKgl4mZl4ZvcoUIViQRJhBBSw2cpC087oc2iZYvBytr8o1ks1FY1LQxh%3Ds0.png)\n",
    "\n",
    "\n",
    "<img src=\"images/transfer2.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://slds-lmu.github.io/seminar_nlp_ss20/figures/02-00-transfer-learning-for-nlp/compare-classical-transferlearning-ml.png)\n",
    "\n",
    "\n",
    "<img src=\"images/PRETRAINED.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://link.springer.com/article/10.1007/s13218-021-00746-2/figures/1)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/multiphased.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://link.springer.com/article/10.1007/s13218-021-00746-2/figures/1)\n",
    "\n",
    "- Top: source network pre-trained on ImageNet. \n",
    "- Bottom: proposed multi-phase fine-tuning approach. The layers to be fine-tuned in the target network are adapted over several phases starting from the top layer.\n",
    "\n",
    "\n",
    "\n",
    "### Understanding of fine-tuning pre-trained models with an example:\n",
    "\n",
    "Most of the world’s text is not in English. To enable researchers and practitioners to build impactful solutions in their domains, understanding how our NLP architectures fare in many languages needs to be more than an afterthought. In this post, we introduce our latest paper that studies multilingual text classification and introduces MultiFiT, a novel method based on ULMFiT. MultiFiT, trained on 100 labeled documents in the target language, outperforms multi-lingual BERT. It also outperforms the cutting-edge LASER algorithm—even though LASER requires a corpus of parallel texts, and MultiFiT does not.\n",
    " \n",
    "\n",
    "<img src=\"images/pre2.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://eisenjulian.github.io/content/images/size/w2000/2020/08/multifit_bootstrapping.png)\n",
    " \n",
    "Visit link for further understanding\n",
    "\n",
    "\n",
    "<img src=\"images/How-does-fine-tuning-pre-trained-models-work (1).png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://d3lkc3n5th01x7.cloudfront.net/wp-content/uploads/2023/02/02020040/How-does-fine-tuning-pre-trained-models-work.png)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "## What is fine-tuning a pre-trained model?\n",
    "The fine-tuning technique is used to optimize a model’s performance on a new or different task. It is used to tailor a model to meet a specific need or domain, say cancer detection, in the field of healthcare. Pre-trained models are fine-tuned by training them on large amounts of labeled data for a certain task, such as Natural Language Processing (NLP) or image classification. Once trained, the model can be applied to similar new tasks or datasets with limited labeled data by fine-tuning the pre-trained model.\n",
    "\n",
    "The fine-tuning process is commonly used in transfer learning, where a pre-trained model is used as a starting point to train a new model for a contrasting but related task. A pre-trained model can significantly diminish the labeled data required to train a new model, making it an effective tool for tasks where labeled data is scarce or expensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74176773",
   "metadata": {},
   "source": [
    "## Unsupervised machine translation and its technique\n",
    "\n",
    "<img src=\"images/svsu.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Task-guidance.png/450px-Task-guidance.png)\n",
    "\n",
    "\n",
    "### Unsupervised Learning\n",
    "So far we have covered the concept of supervised learning as well as common machine learning algorithms for both regression and classification problems. Now let’s talk about the second approach in the whole spectrum of machine learning, which is unsupervised learning.\n",
    "\n",
    "In contrast with supervised learning, we don’t need to provide the model with the ground truth label of each data point during the training process. This means that the model will  learn the pattern of data points by itself, hence the name ‘unsupervised’.\n",
    "\n",
    "In real life application, unsupervised learning is a very useful method since most of the data are unlabeled and the fact that it’s very time consuming to provide a ground-truth label for each data point.\n",
    "\n",
    "There are a lot of examples of use cases that use the unsupervised learning approach, such as dimensionality reduction, clustering, and anomaly detection.\n",
    "\n",
    "<img src=\"images/differencesupervised.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://www.stratascratch.com/blog/supervised-vs-unsupervised-learning/)\n",
    "\n",
    "### What is unsupervised Learning?\n",
    "\n",
    "Unsupervised learning is defined as machine learning model training technique in which machine learning models are not provided with any labelled data, and they must learn from the input/environment themselves. Unsupervised machine-learning techniques try to find patterns in a pool of unlabelled examples (even though such an example is missing some information by definition). The unsupervised learning is primarily of two types:\n",
    "\n",
    "- Clustering: This method of unsupervised learning relies on creating clusters from the input data. The datapoints that have similarities will result in belonging to same clusters, and using those clusters, the predictions will be made.\n",
    "- \n",
    "- Association: The second method of unsupervised learning is association, in which the algorithms find the rules from the input data and the predictions are then made based on those rules and the data.\n",
    "\n",
    "Here are key points regarding unsupervised machine learning:\n",
    "\n",
    "- The training dataset is a pool of unlabelled examples.\n",
    "- The goal of an unsupervised learning is discover hidden pattern within the dataset where the output is not predefined.\n",
    "- Unsupervised learning models can solve complex clustering and association problems.\n",
    "- Some of the examples of unsupervised learning algorithms includesthe following:\n",
    "-      Hierarchical clustering.\n",
    "-      K-means clustering.\n",
    "-      Principal component analysis\n",
    "-      DBSCAN\n",
    "-      A priori algorithm for association\n",
    "\n",
    "Some real-world examples of applications leveraging unsupervised learning algorithms include customer segmentation, user profiling, fraud detection, machine quality inspection, machine failure prediction etc.\n",
    "\n",
    "<img src=\"images/\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://vitalflux.com/wp-content/uploads/2021/11/supervised-vs-unsupervised-machine-learning-768x624.png)\n",
    "\n",
    "\n",
    "<img src=\"images/\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source]()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf47ad2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
