{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1228e8b1",
   "metadata": {},
   "source": [
    "# Week 5_ Sequence-to-Sequence Models\n",
    "\n",
    "- Introduction to sequence-to-sequence models and its architecture\n",
    "- Understanding of Encoder-Decoder Models and its variants\n",
    "- Introduction to attention mechanism and its role in sequence-to-sequence models\n",
    "- Understanding of Beam Search and its application in sequence-to-sequence models\n",
    "- Implementing machine translation models using PyTorch or TensorFlow\n",
    "- Understanding of evaluation metrics for machine translation\n",
    "- Understanding of transfer learning and fine-tuning pre-trained models for machine translation tasks\n",
    "- Introduction to unsupervised machine translation and its techniques\n",
    "- Understanding of Multilingual models and its application in NLP tasks\n",
    "- Understanding the concept of zero-shot learning and its application in machine translation tasks\n",
    "- Understanding the concept of back-translation and its application in machine translation tasks\n",
    "- Understanding the concept of ensembling in machine translation tasks\n",
    "- Understanding the concept of language model pre-training and its application in machine translation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92890111",
   "metadata": {},
   "source": [
    "##  Sequence-to-sequence models and its architecture\n",
    "\n",
    "Sequence to Sequence (often abbreviated to seq2seq) models is a special class of Recurrent Neural Network architectures that we typically use (but not restricted) to solve complex Language problems like Machine Translation, Question Answering, creating Chatbots, Text Summarization, etc.\n",
    "\n",
    "<img src=\"images/sequence.jpg\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://miro.medium.com/v2/resize:fit:669/0*iDgmgGnrzq65dPXy.jpg)\n",
    "\n",
    "\n",
    "<img src=\"images/sequence 1.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://miro.medium.com/v2/resize:fit:700/1*y4D1XNJQmx-Gii1oHeHy_A.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53325aa",
   "metadata": {},
   "source": [
    "## Encoder-Decoder Models and its variants\n",
    "\n",
    "#### The Encoder-Decoder Network\n",
    "\n",
    "This network have been applied to very wide range of applications including machine translation, text summarisation, questioning answering and dialogue. Let’s try to understand the idea underlying the encoder-decoder networks. The encoder takes the input sequence and creates a contextual representation (which is also called context) of it and the decoder takes this contextual representation as input and generates output sequence.\n",
    "\n",
    "<img src=\"images/encoder decoder core.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "### Encoder:\n",
    "\n",
    "Encoder takes the input sequence and generated a context which is the essence of the input to the decoder.\n",
    "\n",
    "<img src=\"images/encoder.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "The entire purpose of the encoder is to generate a contextual representation/ context for the input sequence.\n",
    "\n",
    "### Decoder:\n",
    "\n",
    "Decoder takes the context as input and generates a sequence of output. When we employ RNN as decoder, the context is the final hidden state of the RNN encoder.\n",
    "\n",
    "<img src=\"images/decoder.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "The first decoder RNN cell takes “CONTEXT” as its prior hidden state. The decoder then generated the output until the end-of-sequence marker is generated.\n",
    "\n",
    "- complete encoder decoder model\n",
    "\n",
    "<img src=\"images/complete encoder decoder.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/nerd-for-tech/nlp-theory-and-code-encoder-decoder-models-part-11-30-e686bcb61dc7)\n",
    "\n",
    "<img src=\"images/encoder decoder 2.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://towardsdatascience.com/what-is-an-encoder-decoder-model-86b3d57c5e1a)\n",
    "\n",
    "### Types of Encoders and Decoders\n",
    "\n",
    "There are two main types of encoder and decoder: \n",
    "- Linear \n",
    "- Nonlinear\n",
    "\n",
    "#### Linear encoders and decoders:\n",
    "\n",
    "These are the most common type. They work by taking an input signal and converting it into an output signal that is proportional to the input.\n",
    "\n",
    "#### Nonlinear encoders and decoders:\n",
    "\n",
    "These are less common but are more versatile. They work by taking an input signal and converting it into an output signal that is not proportional to the input.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bedd899",
   "metadata": {},
   "source": [
    "## Introduction to attention mechanism and its role in sequence-to-sequence models\n",
    "\n",
    "<img src=\"images/attention mechanism.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://miro.medium.com/v2/resize:fit:1022/1*qhOlQHLdtfZORIXYuoCtaA.png)\n",
    "\n",
    "\n",
    "\n",
    "Seq2Seq model with an attention mechanism consists of an encoder, decoder, and attention layer.\n",
    "\n",
    "Attention layer consists of\n",
    "\n",
    "- Alignment layer\n",
    "- Attention weights\n",
    "- Context vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbd36cd",
   "metadata": {},
   "source": [
    "## Understanding of Beam Search and its application in sequence-to-sequence models\n",
    "\n",
    "\n",
    "<img src=\"images/beam1.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/@dhartidhami/beam-search-in-seq2seq-model-7606d55b21a5)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/beam2.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/@dhartidhami/beam-search-in-seq2seq-model-7606d55b21a5)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/beam3.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://medium.com/@dhartidhami/beam-search-in-seq2seq-model-7606d55b21a5)\n",
    "\n",
    "\n",
    "### APPLICATIONS \n",
    "\n",
    "A beam search is most often used to maintain tractability in large systems with insufficient memory to store the entire search tree.For example, \n",
    "- It has been used in many machine translation systems.\n",
    "- Each part is processed to select the best translation, and many different ways of translating the words appear.\n",
    "- According to their sentence structures, the top best translations are kept, and the rest are discarded. The translator then evaluates the translations according to a given criterion, choosing the translation which best keeps the goals.\n",
    "- The first use of a beam search was in the Harpy Speech Recognition System, CMU 1976."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb65f9a",
   "metadata": {},
   "source": [
    " ## Evaluation metrics for machine translation\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "<img src=\"images/evaluation matrices.png\"  width =\"1000px\" height =\"1000px\">\n",
    "\n",
    "Image source: [Link to source](https://www.mdpi.com/2227-7390/11/4/1006)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82d8d23",
   "metadata": {},
   "source": [
    "## Transfer learning and fine-tuning pre-trained models for machine translation tasks\n",
    "\n",
    "\n",
    "<img src=\"images/transferlearning.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/616b35e3dcd432047dd02ea5_uYLdnVpAfjC3DC7eWJM2xWyQin_dbVcak0JlRpd7S2bAkdylh-9JITWttww3Wq8fKI56Tl3_v7Y-aVh4nKgl4mZl4ZvcoUIViQRJhBBSw2cpC087oc2iZYvBytr8o1ks1FY1LQxh%3Ds0.png)\n",
    "\n",
    "\n",
    "<img src=\"images/transfer2.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://slds-lmu.github.io/seminar_nlp_ss20/figures/02-00-transfer-learning-for-nlp/compare-classical-transferlearning-ml.png)\n",
    "\n",
    "\n",
    "<img src=\"images/PRETRAINED.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://link.springer.com/article/10.1007/s13218-021-00746-2/figures/1)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/multiphased.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://link.springer.com/article/10.1007/s13218-021-00746-2/figures/1)\n",
    "\n",
    "- Top: source network pre-trained on ImageNet. \n",
    "- Bottom: proposed multi-phase fine-tuning approach. The layers to be fine-tuned in the target network are adapted over several phases starting from the top layer.\n",
    "\n",
    "\n",
    "\n",
    "### Understanding of fine-tuning pre-trained models with an example:\n",
    "\n",
    "Most of the world’s text is not in English. To enable researchers and practitioners to build impactful solutions in their domains, understanding how our NLP architectures fare in many languages needs to be more than an afterthought. In this post, we introduce our latest paper that studies multilingual text classification and introduces MultiFiT, a novel method based on ULMFiT. MultiFiT, trained on 100 labeled documents in the target language, outperforms multi-lingual BERT. It also outperforms the cutting-edge LASER algorithm—even though LASER requires a corpus of parallel texts, and MultiFiT does not.\n",
    " \n",
    "\n",
    "<img src=\"images/pre2.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://eisenjulian.github.io/content/images/size/w2000/2020/08/multifit_bootstrapping.png)\n",
    " \n",
    "Visit link for further understanding\n",
    "\n",
    "\n",
    "<img src=\"images/How-does-fine-tuning-pre-trained-models-work (1).png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://d3lkc3n5th01x7.cloudfront.net/wp-content/uploads/2023/02/02020040/How-does-fine-tuning-pre-trained-models-work.png)\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "## What is fine-tuning a pre-trained model?\n",
    "The fine-tuning technique is used to optimize a model’s performance on a new or different task. It is used to tailor a model to meet a specific need or domain, say cancer detection, in the field of healthcare. Pre-trained models are fine-tuned by training them on large amounts of labeled data for a certain task, such as Natural Language Processing (NLP) or image classification. Once trained, the model can be applied to similar new tasks or datasets with limited labeled data by fine-tuning the pre-trained model.\n",
    "\n",
    "The fine-tuning process is commonly used in transfer learning, where a pre-trained model is used as a starting point to train a new model for a contrasting but related task. A pre-trained model can significantly diminish the labeled data required to train a new model, making it an effective tool for tasks where labeled data is scarce or expensive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec6b4aa",
   "metadata": {},
   "source": [
    "## Unsupervised machine translation and its technique\n",
    "\n",
    "<img src=\"images/svsu.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Task-guidance.png/450px-Task-guidance.png)\n",
    "\n",
    "\n",
    "### Unsupervised Learning\n",
    "So far we have covered the concept of supervised learning as well as common machine learning algorithms for both regression and classification problems. Now let’s talk about the second approach in the whole spectrum of machine learning, which is unsupervised learning.\n",
    "\n",
    "In contrast with supervised learning, we don’t need to provide the model with the ground truth label of each data point during the training process. This means that the model will  learn the pattern of data points by itself, hence the name ‘unsupervised’.\n",
    "\n",
    "In real life application, unsupervised learning is a very useful method since most of the data are unlabeled and the fact that it’s very time consuming to provide a ground-truth label for each data point.\n",
    "\n",
    "There are a lot of examples of use cases that use the unsupervised learning approach, such as dimensionality reduction, clustering, and anomaly detection.\n",
    "\n",
    "<img src=\"images/differencesupervised.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://www.stratascratch.com/blog/supervised-vs-unsupervised-learning/)\n",
    "\n",
    "### What is unsupervised Learning?\n",
    "\n",
    "\n",
    "<img src=\"images/supervised-vs-unsupervised-machine-learning-768x624.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://vitalflux.com/wp-content/uploads/2021/11/supervised-vs-unsupervised-machine-learning-768x624.png)\n",
    "\n",
    "\n",
    "Unsupervised learning is defined as machine learning model training technique in which machine learning models are not provided with any labelled data, and they must learn from the input/environment themselves. Unsupervised machine-learning techniques try to find patterns in a pool of unlabelled examples (even though such an example is missing some information by definition). The unsupervised learning is primarily of two types:\n",
    "\n",
    "- Clustering: This method of unsupervised learning relies on creating clusters from the input data. The datapoints that have similarities will result in belonging to same clusters, and using those clusters, the predictions will be made.\n",
    "- \n",
    "- Association: The second method of unsupervised learning is association, in which the algorithms find the rules from the input data and the predictions are then made based on those rules and the data.\n",
    "\n",
    "Here are key points regarding unsupervised machine learning:\n",
    "\n",
    "- The training dataset is a pool of unlabelled examples.\n",
    "- The goal of an unsupervised learning is discover hidden pattern within the dataset where the output is not predefined.\n",
    "- Unsupervised learning models can solve complex clustering and association problems.\n",
    "- Some of the examples of unsupervised learning algorithms includesthe following:\n",
    "-      Hierarchical clustering.\n",
    "-      K-means clustering.\n",
    "-      Principal component analysis\n",
    "-      DBSCAN\n",
    "-      A priori algorithm for association\n",
    "\n",
    "Some real-world examples of applications leveraging unsupervised learning algorithms include customer segmentation, user profiling, fraud detection, machine quality inspection, machine failure prediction etc.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e17a1f",
   "metadata": {},
   "source": [
    "## Multilingual models and its application in NLP tasks\n",
    "\n",
    "### What is multilingual Natural Language Processing (NLP)? \n",
    "\n",
    "Multilingual NLP is a technology that integrates linguistics, artificial intelligence, and computer science to serve the purpose of processing and analyzing substantial amounts of natural human language in numerous settings.\n",
    "\n",
    "<img src=\"images/multi 1.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://stagezero.ai/blog/multilingual-nlp-solutions/)\n",
    "\n",
    "\n",
    "### How does multilingual NLP work? \n",
    "\n",
    "There are many different forms of multilingual NLP, but in general, it enables computational software to understand the language of certain texts, along with contextual nuances. Multilingual NLP is also capable of obtaining specific data and delivering key insights. In short, multilingual NLP technology makes the impossible possible which is to process and analyze large amounts of data. Without it, this kind of task can probably only be executed by employing a very labor- and time-intensive approach. \n",
    "\n",
    "\n",
    "- HOW MULTILINGUAL NLP CAN BREAK DOWN LANGUAGE BARRIERS\n",
    "There have been recent advancements in building models which will help to cater to a diverse spectrum of languages, helping researchers overcome the biggest causes of language barriers.\n",
    "\n",
    "<img src=\"images/multi 2.png\" width =\"1000px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://www.allerin.com/wp-blog/wp-content/uploads/2022/07/How-Multilingual-NLP-Can-Break-Down-Language-Barriers.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560faf96",
   "metadata": {},
   "source": [
    "#  zero-shot learning and its application in machine translation tasks\n",
    "\n",
    "## What is Zero-Shot Learning?\n",
    "Transfer learning finds its inspiration in human’s capacity to generalize from experience. Humans are very good at using previous knowledge to handle new situations. For instance, a person that speaks Swedish can use his experience to learn a similar language to Norwegian.\n",
    "\n",
    "Zero-shot learning (ZSL) is a form of transfer learning that aims to learn patterns from labeled data in order to detect classes that were never seen during training.  As the lack of labeled data and scalability is a regular problem in machine learning applications, ZSL has gained much attention in recent years thanks to its ability to predict unseen classes.\n",
    "\n",
    "\n",
    "<img src=\"images/zero 1.jpg\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://modulai.io/wp-content/uploads/2022/08/ZSL_example_updated-1280x757.jpg)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/zero 2.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://editor.analyticsvidhya.com/uploads/68432img3.PNG)\n",
    "\n",
    "<img src=\"images/zero 3.jpg\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://opendatascience.com/wp-content/uploads/2019/11/Creativity-Inspired-Zero-shot-Learning-2-640x300.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4def443c",
   "metadata": {},
   "source": [
    "# Back-translation and its application in machine translation tasks\n",
    "\n",
    "\n",
    "## What is back translation?\n",
    "\n",
    "Back translation, also called reverse translation, is the process of re-translating content from the target language back to its source language in literal terms. For example, if you’re translating content from English to Swedish, the translator would also write a back translation English so the intention of the translated option is easily understood. Back translations don’t impact the translation memory or other resources like glossaries used by the translator.\n",
    "\n",
    "Back translation (sometimes referred to as double translation) is most helpful when the content at hand includes taglines, slogans, titles, product names, clever phrases and puns because the implied meaning of the content in one language doesn’t necessarily work for another language or region. The back translation offers the content owner the opportunity to review what creative liberties the translators took to adapt the content for their market. And oftentimes, for content that is this complex, the translator will offer multiple options so the source content owner can make a decision that makes the most sense for the brand.\n",
    "\n",
    "This is often confused with double translation, which is a method of translation where one translator creates multiple versions of a piece of content to account for the nuances in different words and phrases.\n",
    "\n",
    "Back translation is often used as a quality assurance method. The back translation process looks like this:\n",
    "\n",
    "- A linguist translates the original source text into the new language.\n",
    "- Then the linguist translates the localized string back into the source language literally to convey the meaning of the translation\n",
    "- The content owner or project manager selects the option that best represent the brand, tone and intention of the source content\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/backtranslation.png\" width =\"900px\" height =\"900px\">\n",
    "\n",
    "Image source: [Link to source](https://repository-images.githubusercontent.com/196985080/c4892580-bef8-11e9-9ba7-b888350d6fa7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a0c93f",
   "metadata": {},
   "source": [
    "# Ensembling in machine translation tasks\n",
    "\n",
    "## What is Ensemble Learning?\n",
    "\n",
    "Ensemble Learning is a method of reaching a consensus in predictions by fusing the salient properties of two or more models. The final ensemble learning framework is more robust than the individual models that constitute the ensemble because ensembling reduces the variance in the prediction errors\n",
    "\n",
    "Ensemble Learning tries to capture complementary information from its different contributing models—that is, an ensemble framework is successful when the contributing models are statistically diverse. \n",
    "\n",
    "In other words, models that display performance variation when evaluated on the same dataset are better suited to form an ensemble.\n",
    "\n",
    "<img src=\"images/ensemble-learning 1.png\" width =\"600px\" height =\"600px\">\n",
    "\n",
    "Image source: [Link to source](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/61f7bbd4e90cce440b88ea32_ensemble-learning.png)\n",
    "\n",
    "## How does ensemble learning work?\n",
    "Ensemble learning combines the mapping functions learned by different classifiers to generate an aggregated mapping function. \n",
    "\n",
    "The diverse methods proposed over the years use different strategies for computing this combination. \n",
    "\n",
    "Below we describe the most popular methods that are commonly used in the literature.\n",
    "- Bagging\n",
    "\n",
    "<img src=\"images/essemble 2.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/61a4414d28946a3ac3e69ed9_q-FrlRMLk-5nSxZ_3ONlFpu5hQ61PsuAxkusTD1vEX5NqkdH2Ie0u_75rIySTZKXVI4VBxM-AIw3APQvRboG3kv-3l3cA5c5qyMwwTMe2OLXzoAgA051Dqbx7XVfdJaDyNwrSLUf.png)\n",
    "\n",
    "- Boosting\n",
    "\n",
    "<img src=\"images/essemble 3.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/61a4414d5e568a661fb7896c_mji7xyiAlyQAdxQde14HY1OVvAVzDyyKhDOo4a4bg53_m2OHUvHhMGexaHuHCfKGRVQQlfFlihuodX7LD5hugPgGw8ZzJV4bHjHc648Zr0LyVr2I0i6ciJvJri_OFCuQpOf81xcn.png)\n",
    "\n",
    "- Stacking\n",
    "\n",
    "<img src=\"images/essemble 4.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/61a4414dba9e9f94d7b31368_RhQ6ctlYepNo3J-yChyk_jLM_siHT9eGIJTpcI0NEPhADEcGic31JW4TWwLLzWv0LvqyDjFx9yQ8m16kKENTtPZeW-fY-9z6k7m-rsmPseGIeHhB-IiI0V5t4hImEPZRnEWPChAo.png)\n",
    "\n",
    "- Mixture of Experts\n",
    "\n",
    "<img src=\"images/essemble 5.png\" width =\"800px\" height =\"800px\">\n",
    "\n",
    "Image source: [Link to source](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/61a4414da1649f856e553d74_jiy3kw7cLPoe3-DClXGWwEZo4FNQuf3NzqSpelWXN0di_Ydnyz9QnHqGiFAd87pc-WELMSXGKKdw1wqeA5pjSioytSVNXCmU6wdaV3nFUYZjkKKs_deV_XyUjLOfU8K9o5RWu_n4.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958e7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
